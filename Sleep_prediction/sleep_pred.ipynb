{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des bibliothèques\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données d'entraînement\n",
    "train_series = dd.read_parquet(\"train_series.parquet\")\n",
    "train_events = pd.read_csv(\"train_events.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>step</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>anglez</th>\n",
       "      <th>enmo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>string</td>\n",
       "      <td>uint32</td>\n",
       "      <td>string</td>\n",
       "      <td>float32</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: to_pyarrow_string, 2 graph layers</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              series_id    step timestamp   anglez     enmo\n",
       "npartitions=1                                              \n",
       "                 string  uint32    string  float32  float32\n",
       "                    ...     ...       ...      ...      ...\n",
       "Dask Name: to_pyarrow_string, 2 graph layers"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusionner les données d'accéléromètre avec les événements de sommeil\n",
    "data = train_series.merge(train_events, on=\"series_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 488. MiB for an array with shape (127946340, 1) and data type uint32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\Documents\\Scolaires\\SUPAERO\\ML_competition\\sleep_acc\\child-mind-institute-detect-sleep-states\\sleep_pred.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Documents/Scolaires/SUPAERO/ML_competition/sleep_acc/child-mind-institute-detect-sleep-states/sleep_pred.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data\u001b[39m.\u001b[39;49mhead()\n",
      "File \u001b[1;32md:\\Documents\\Scolaires\\SUPAERO\\ML_competition\\mlenv\\lib\\site-packages\\dask\\dataframe\\core.py:1437\u001b[0m, in \u001b[0;36m_Frame.head\u001b[1;34m(self, n, npartitions, compute)\u001b[0m\n\u001b[0;32m   1435\u001b[0m \u001b[39m# No need to warn if we're already looking at all partitions\u001b[39;00m\n\u001b[0;32m   1436\u001b[0m safe \u001b[39m=\u001b[39m npartitions \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnpartitions\n\u001b[1;32m-> 1437\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_head(n\u001b[39m=\u001b[39;49mn, npartitions\u001b[39m=\u001b[39;49mnpartitions, compute\u001b[39m=\u001b[39;49mcompute, safe\u001b[39m=\u001b[39;49msafe)\n",
      "File \u001b[1;32md:\\Documents\\Scolaires\\SUPAERO\\ML_competition\\mlenv\\lib\\site-packages\\dask\\dataframe\\core.py:1471\u001b[0m, in \u001b[0;36m_Frame._head\u001b[1;34m(self, n, npartitions, compute, safe)\u001b[0m\n\u001b[0;32m   1466\u001b[0m result \u001b[39m=\u001b[39m new_dd_object(\n\u001b[0;32m   1467\u001b[0m     graph, name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_meta, [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdivisions[\u001b[39m0\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdivisions[npartitions]]\n\u001b[0;32m   1468\u001b[0m )\n\u001b[0;32m   1470\u001b[0m \u001b[39mif\u001b[39;00m compute:\n\u001b[1;32m-> 1471\u001b[0m     result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39;49mcompute()\n\u001b[0;32m   1472\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\Documents\\Scolaires\\SUPAERO\\ML_competition\\mlenv\\lib\\site-packages\\dask\\base.py:342\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    319\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \n\u001b[0;32m    321\u001b[0m \u001b[39m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[39m    dask.compute\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 342\u001b[0m     (result,) \u001b[39m=\u001b[39m compute(\u001b[39mself\u001b[39m, traverse\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    343\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\Documents\\Scolaires\\SUPAERO\\ML_competition\\mlenv\\lib\\site-packages\\dask\\base.py:628\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[0;32m    625\u001b[0m     postcomputes\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m    627\u001b[0m \u001b[39mwith\u001b[39;00m shorten_traceback():\n\u001b[1;32m--> 628\u001b[0m     results \u001b[39m=\u001b[39m schedule(dsk, keys, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    630\u001b[0m \u001b[39mreturn\u001b[39;00m repack([f(r, \u001b[39m*\u001b[39ma) \u001b[39mfor\u001b[39;00m r, (f, a) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[1;32md:\\Documents\\Scolaires\\SUPAERO\\ML_competition\\mlenv\\lib\\site-packages\\dask\\dataframe\\io\\parquet\\core.py:96\u001b[0m, in \u001b[0;36mParquetFunctionWrapper.__call__\u001b[1;34m(self, part)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(part, \u001b[39mlist\u001b[39m):\n\u001b[0;32m     94\u001b[0m     part \u001b[39m=\u001b[39m [part]\n\u001b[1;32m---> 96\u001b[0m \u001b[39mreturn\u001b[39;00m read_parquet_part(\n\u001b[0;32m     97\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfs,\n\u001b[0;32m     98\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine,\n\u001b[0;32m     99\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmeta,\n\u001b[0;32m    100\u001b[0m     [\n\u001b[0;32m    101\u001b[0m         \u001b[39m# Temporary workaround for HLG serialization bug\u001b[39;49;00m\n\u001b[0;32m    102\u001b[0m         \u001b[39m# (see: https://github.com/dask/dask/issues/8581)\u001b[39;49;00m\n\u001b[0;32m    103\u001b[0m         (p\u001b[39m.\u001b[39;49mdata[\u001b[39m\"\u001b[39;49m\u001b[39mpiece\u001b[39;49m\u001b[39m\"\u001b[39;49m], p\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mkwargs\u001b[39;49m\u001b[39m\"\u001b[39;49m, {}))\n\u001b[0;32m    104\u001b[0m         \u001b[39mif\u001b[39;49;00m \u001b[39mhasattr\u001b[39;49m(p, \u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    105\u001b[0m         \u001b[39melse\u001b[39;49;00m (p[\u001b[39m\"\u001b[39;49m\u001b[39mpiece\u001b[39;49m\u001b[39m\"\u001b[39;49m], p\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mkwargs\u001b[39;49m\u001b[39m\"\u001b[39;49m, {}))\n\u001b[0;32m    106\u001b[0m         \u001b[39mfor\u001b[39;49;00m p \u001b[39min\u001b[39;49;00m part\n\u001b[0;32m    107\u001b[0m     ],\n\u001b[0;32m    108\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns,\n\u001b[0;32m    109\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex,\n\u001b[0;32m    110\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcommon_kwargs,\n\u001b[0;32m    111\u001b[0m )\n",
      "File \u001b[1;32md:\\Documents\\Scolaires\\SUPAERO\\ML_competition\\mlenv\\lib\\site-packages\\dask\\dataframe\\io\\parquet\\core.py:659\u001b[0m, in \u001b[0;36mread_parquet_part\u001b[1;34m(fs, engine, meta, part, columns, index, kwargs)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(part) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m part[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m] \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m check_multi_support(engine):\n\u001b[0;32m    657\u001b[0m     \u001b[39m# Part kwargs expected\u001b[39;00m\n\u001b[0;32m    658\u001b[0m     func \u001b[39m=\u001b[39m engine\u001b[39m.\u001b[39mread_partition\n\u001b[1;32m--> 659\u001b[0m     dfs \u001b[39m=\u001b[39m [\n\u001b[0;32m    660\u001b[0m         func(\n\u001b[0;32m    661\u001b[0m             fs,\n\u001b[0;32m    662\u001b[0m             rg,\n\u001b[0;32m    663\u001b[0m             columns\u001b[39m.\u001b[39mcopy(),\n\u001b[0;32m    664\u001b[0m             index,\n\u001b[0;32m    665\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtoolz\u001b[39m.\u001b[39mmerge(kwargs, kw),\n\u001b[0;32m    666\u001b[0m         )\n\u001b[0;32m    667\u001b[0m         \u001b[39mfor\u001b[39;00m (rg, kw) \u001b[39min\u001b[39;00m part\n\u001b[0;32m    668\u001b[0m     ]\n\u001b[0;32m    669\u001b[0m     df \u001b[39m=\u001b[39m concat(dfs, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(dfs) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m dfs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    670\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    671\u001b[0m     \u001b[39m# No part specific kwargs, let engine read\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39m# list of parts at once\u001b[39;00m\n",
      "File \u001b[1;32md:\\Documents\\Scolaires\\SUPAERO\\ML_competition\\mlenv\\lib\\site-packages\\dask\\dataframe\\io\\parquet\\core.py:660\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(part) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m part[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m] \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m check_multi_support(engine):\n\u001b[0;32m    657\u001b[0m     \u001b[39m# Part kwargs expected\u001b[39;00m\n\u001b[0;32m    658\u001b[0m     func \u001b[39m=\u001b[39m engine\u001b[39m.\u001b[39mread_partition\n\u001b[0;32m    659\u001b[0m     dfs \u001b[39m=\u001b[39m [\n\u001b[1;32m--> 660\u001b[0m         func(\n\u001b[0;32m    661\u001b[0m             fs,\n\u001b[0;32m    662\u001b[0m             rg,\n\u001b[0;32m    663\u001b[0m             columns\u001b[39m.\u001b[39mcopy(),\n\u001b[0;32m    664\u001b[0m             index,\n\u001b[0;32m    665\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtoolz\u001b[39m.\u001b[39mmerge(kwargs, kw),\n\u001b[0;32m    666\u001b[0m         )\n\u001b[0;32m    667\u001b[0m         \u001b[39mfor\u001b[39;00m (rg, kw) \u001b[39min\u001b[39;00m part\n\u001b[0;32m    668\u001b[0m     ]\n\u001b[0;32m    669\u001b[0m     df \u001b[39m=\u001b[39m concat(dfs, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(dfs) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m dfs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    670\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    671\u001b[0m     \u001b[39m# No part specific kwargs, let engine read\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39m# list of parts at once\u001b[39;00m\n",
      "File \u001b[1;32md:\\Documents\\Scolaires\\SUPAERO\\ML_competition\\mlenv\\lib\\site-packages\\dask\\dataframe\\io\\parquet\\arrow.py:688\u001b[0m, in \u001b[0;36mArrowDatasetEngine.read_partition\u001b[1;34m(cls, fs, pieces, columns, index, dtype_backend, categories, partitions, filters, schema, **kwargs)\u001b[0m\n\u001b[0;32m    686\u001b[0m         index \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    687\u001b[0m         columns_and_parts \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(columns_and_parts) \u001b[39m-\u001b[39m \u001b[39mset\u001b[39m(df\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mnames))\n\u001b[1;32m--> 688\u001b[0m df \u001b[39m=\u001b[39m df[\u001b[39mlist\u001b[39;49m(columns_and_parts)]\n\u001b[0;32m    690\u001b[0m \u001b[39mif\u001b[39;00m index:\n\u001b[0;32m    691\u001b[0m     df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mset_index(index)\n",
      "File \u001b[1;32md:\\Documents\\Scolaires\\SUPAERO\\ML_competition\\mlenv\\lib\\site-packages\\pandas\\core\\array_algos\\take.py:156\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    150\u001b[0m out_shape \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(out_shape_)\n\u001b[0;32m    151\u001b[0m \u001b[39mif\u001b[39;00m arr\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mf_contiguous \u001b[39mand\u001b[39;00m axis \u001b[39m==\u001b[39m arr\u001b[39m.\u001b[39mndim \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    152\u001b[0m     \u001b[39m# minor tweak that can make an order-of-magnitude difference\u001b[39;00m\n\u001b[0;32m    153\u001b[0m     \u001b[39m# for dataframes initialized directly from 2-d ndarrays\u001b[39;00m\n\u001b[0;32m    154\u001b[0m     \u001b[39m# (s.t. df.values is c-contiguous and df._mgr.blocks[0] is its\u001b[39;00m\n\u001b[0;32m    155\u001b[0m     \u001b[39m# f-contiguous transpose)\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m     out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mempty(out_shape, dtype\u001b[39m=\u001b[39;49mdtype, order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mF\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    157\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(out_shape, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 488. MiB for an array with shape (127946340, 1) and data type uint32"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "# Load the data using Dask\n",
    "data = dd.read_csv(\"path/to/data.csv\")\n",
    "\n",
    "# Print the first few rows of the data\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer des caractéristiques (exemples : moyenne et écart-type de 'enmo')\n",
    "features = data.groupby(\"series_id\")[\"enmo\"].agg([\"mean\", \"std\"]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer des étiquettes (binaire : 1 pour \"onset\", 0 pour \"wakeup\")\n",
    "data[\"event\"] = data[\"event\"].map({\"onset\": 1, \"wakeup\": 0})\n",
    "labels = data.groupby(\"series_id\")[\"event\"].max().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels[\"event\"], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner le modèle de régression logistique\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluer les performances du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Précision du modèle : {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# Matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Matrice de confusion :\\n\", conf_matrix)\n",
    "\n",
    "# Rapport de classification\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Rapport de classification :\\n\", class_report)\n",
    "\n",
    "# Tracé de la régression logistique\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(features[\"mean\"], labels[\"event\"], c=\"b\", label=\"Données réelles\")\n",
    "plt.plot(X_test[\"mean\"], y_pred, c=\"r\", label=\"Régression logistique\")\n",
    "plt.xlabel(\"Moyenne de 'enmo'\")\n",
    "plt.ylabel(\"Événement (1 pour onset, 0 pour wakeup)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# affiche le mse\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
